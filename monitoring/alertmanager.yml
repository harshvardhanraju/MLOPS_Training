# Alertmanager configuration for MLOps notifications
global:
  # Global SMTP configuration
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alertmanager@mlops-demo.com'
  smtp_auth_username: 'alertmanager@mlops-demo.com'
  # smtp_auth_password: 'your-smtp-password'

  # Global Slack configuration
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

# The directory from which notification templates are read
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# The root route on which each incoming alert enters
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'

  routes:
    # ML/DS team alerts
    - match:
        team: ml-ops
      receiver: 'ml-ops-team'
      group_wait: 5s
      repeat_interval: 4h

    - match:
        team: data-science
      receiver: 'data-science-team'
      group_wait: 10s
      repeat_interval: 8h

    # Critical alerts (immediate notification)
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 30m

    # Infrastructure team
    - match:
        team: infrastructure
      receiver: 'infrastructure-team'
      group_wait: 5s
      repeat_interval: 2h

    # Component-specific routing
    - match:
        component: model-performance
      receiver: 'model-performance-alerts'

    - match:
        component: data-quality
      receiver: 'data-quality-alerts'

# Inhibition rules allow to mute a set of alerts given that another alert is firing
inhibit_rules:
  # Inhibit warning if critical alert is firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

  # Inhibit service alerts if the entire instance is down
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '(HighCPUUsage|HighMemoryUsage|DiskSpaceLow)'
    equal: ['instance']

receivers:
  # Default receiver for uncategorized alerts
  - name: 'default'
    email_configs:
      - to: 'alerts@mlops-demo.com'
        subject: '[ALERT] {{ .GroupLabels.alertname }} - {{ .GroupLabels.instance }}'
        body: |
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Severity:** {{ .Labels.severity }}
          **Instance:** {{ .Labels.instance }}
          **Started:** {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}

  # ML Operations team notifications
  - name: 'ml-ops-team'
    slack_configs:
      - channel: '#ml-ops-alerts'
        username: 'AlertManager'
        icon_emoji: ':warning:'
        title: 'MLOps Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Model:* {{ .Labels.model_name }}
          *Instance:* {{ .Labels.instance }}
          *Started:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        color: |
          {{ if eq .Status "firing" }}
            {{ if eq .GroupLabels.severity "critical" }}danger{{ else }}warning{{ end }}
          {{ else }}good{{ end }}

    email_configs:
      - to: 'ml-ops-team@mlops-demo.com'
        subject: '[MLOps] {{ .Status | toUpper }} - {{ .GroupLabels.alertname }}'
        html: |
          <h2>MLOps Alert Notification</h2>
          <table border="1" cellpadding="5">
            <tr><th>Alert</th><th>Status</th><th>Severity</th><th>Description</th><th>Instance</th><th>Started</th></tr>
            {{ range .Alerts }}
            <tr>
              <td>{{ .Annotations.summary }}</td>
              <td>{{ .Status }}</td>
              <td>{{ .Labels.severity }}</td>
              <td>{{ .Annotations.description }}</td>
              <td>{{ .Labels.instance }}</td>
              <td>{{ .StartsAt.Format "2006-01-02 15:04:05" }}</td>
            </tr>
            {{ end }}
          </table>

  # Data Science team notifications
  - name: 'data-science-team'
    email_configs:
      - to: 'data-science@mlops-demo.com'
        subject: '[Data Science Alert] {{ .GroupLabels.alertname }}'
        body: |
          Data Quality Alert Notification

          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Model: {{ .Labels.model_name }}
          Feature: {{ .Labels.feature_name }}
          Severity: {{ .Labels.severity }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ if .Annotations.runbook_url }}
          Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
          {{ end }}

  # Critical alerts with immediate notification
  - name: 'critical-alerts'
    slack_configs:
      - channel: '#critical-alerts'
        username: 'AlertManager-Critical'
        icon_emoji: ':rotating_light:'
        title: 'CRITICAL ALERT: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          :rotating_light: *CRITICAL ALERT* :rotating_light:

          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Instance:* {{ .Labels.instance }}
          *Started:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}

          Immediate action required!
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        color: 'danger'

    # You could add PagerDuty for critical alerts
    # pagerduty_configs:
    #   - routing_key: 'your-pagerduty-integration-key'
    #     description: '{{ .GroupLabels.alertname }}: {{ .GroupLabels.instance }}'

  # Infrastructure team notifications
  - name: 'infrastructure-team'
    email_configs:
      - to: 'infrastructure@mlops-demo.com'
        subject: '[Infrastructure] {{ .Status | toUpper }} - {{ .GroupLabels.alertname }}'
        body: |
          Infrastructure Alert

          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Component: {{ .Labels.component }}
          Instance: {{ .Labels.instance }}
          Severity: {{ .Labels.severity }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}

  # Model performance specific alerts
  - name: 'model-performance-alerts'
    slack_configs:
      - channel: '#model-performance'
        title: 'Model Performance Alert'
        text: |
          {{ range .Alerts }}
          *Model:* {{ .Labels.model_name }}
          *Alert:* {{ .Annotations.summary }}
          *Details:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}

  # Data quality specific alerts
  - name: 'data-quality-alerts'
    email_configs:
      - to: 'data-quality@mlops-demo.com'
        subject: '[Data Quality] {{ .GroupLabels.alertname }}'
        body: |
          Data Quality Issue Detected

          {{ range .Alerts }}
          Model: {{ .Labels.model_name }}
          Feature: {{ .Labels.feature_name }}
          Issue: {{ .Annotations.summary }}
          Details: {{ .Annotations.description }}
          Drift Score: {{ .Value }}
          {{ end }}